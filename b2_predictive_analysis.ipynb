{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27abb3ed",
   "metadata": {},
   "source": [
    "# Task B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5deb1b6a",
   "metadata": {},
   "source": [
    "The steps performed will be:\n",
    "\n",
    "- Model Training\n",
    "\n",
    "- Model Management\n",
    "\n",
    "    Use MLflow (or a similar model management framework) to track the entire pipeline, including models, hyperparameters, evaluation metrics, and tagging the best model for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2dd588b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set HADOOP_HOME to the parent folder of the 'bin' with winutils.exe\n",
    "os.environ[\"HADOOP_HOME\"] = r\"C:\\winutils-master\\hadoop-3.0.0\"\n",
    "os.environ[\"PATH\"] += r\";C:\\winutils-master\\hadoop-3.0.0\\bin\"\n",
    "\n",
    "# (Optional: Set JAVA_HOME if not already set)\n",
    "os.environ[\"JAVA_HOME\"] = r\"C:\\Program Files\\Eclipse Adoptium\\jdk-17.0.15.6-hotspot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93900788",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, avg, sqrt, abs as spark_abs\n",
    "from pyspark.ml.regression import LinearRegression, RandomForestRegressor, GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "import time\n",
    "import mlflow\n",
    "import mlflow.spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a187df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"PredictiveAnalysis\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e1bd055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the path for exploitation zone\n",
    "exploitation_zone = \"exploitation_zone\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55b367be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load preprocessed data\n",
    "train_data = spark.read.parquet(f\"{exploitation_zone}/train_data\")\n",
    "test_data = spark.read.parquet(f\"{exploitation_zone}/test_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af7a7e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------------------+\n",
      "|price_clean|            features|        neighborhood|\n",
      "+-----------+--------------------+--------------------+\n",
      "|    39000.0|(91,[0,1,2,3,4,5,...|El Poble Sec - Pa...|\n",
      "|    60000.0|(91,[0,1,2,3,4,5,...|          La Bordeta|\n",
      "|    69500.0|(91,[0,1,2,3,4,5,...|               Sants|\n",
      "|    70000.0|(91,[0,1,2,3,4,5,...|  La Marina del Port|\n",
      "|    79900.0|(91,[0,2,3,4,5,6,...|El Poble Sec - Pa...|\n",
      "+-----------+--------------------+--------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "train_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d15990f",
   "metadata": {},
   "source": [
    "## Model Training and Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "562e4246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create 3 different ML models: Linear Regression, Random Forest, and Gradient Boosted Trees\n",
    "\n",
    "# Linear Regression model\n",
    "linear_regression = LinearRegression(\n",
    "    featuresCol=\"features\", \n",
    "    labelCol=\"price_clean\",\n",
    "    predictionCol=\"prediction\")\n",
    "\n",
    "# Random Forest model\n",
    "random_forest = RandomForestRegressor(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"price_clean\", \n",
    "    predictionCol=\"prediction\",\n",
    "    numTrees=50,\n",
    "    maxDepth=10,\n",
    "    seed=42)\n",
    "\n",
    "# Gradient Boosted Trees model\n",
    "gradient_boosting = GBTRegressor(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"price_clean\",\n",
    "    predictionCol=\"prediction\", \n",
    "    maxIter=50,\n",
    "    maxDepth=8,\n",
    "    seed=42)\n",
    "\n",
    "models = {\n",
    "    \"Linear Regression\": linear_regression,\n",
    "    \"Random Forest\": random_forest, \n",
    "    \"Gradient Boosting\": gradient_boosting}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "549fde88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameter grids for each model to optimize hyperparameters\n",
    "\n",
    "# Linear Regression parameter grid\n",
    "lr_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(linear_regression.regParam, [0.01, 0.1, 1.0]) \\\n",
    "    .addGrid(linear_regression.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
    "    .build()\n",
    "\n",
    "# Random Forest parameter grid\n",
    "rf_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(random_forest.numTrees, [30, 50, 100]) \\\n",
    "    .addGrid(random_forest.maxDepth, [5, 10, 15]) \\\n",
    "    .build()\n",
    "\n",
    "# Gradient Boosting parameter grid  \n",
    "gb_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(gradient_boosting.maxIter, [30, 50, 100]) \\\n",
    "    .addGrid(gradient_boosting.maxDepth, [5, 8, 10]) \\\n",
    "    .build()\n",
    "\n",
    "param_grids = {\n",
    "    \"Linear Regression\": lr_param_grid,\n",
    "    \"Random Forest\": rf_param_grid,\n",
    "    \"Gradient Boosting\": gb_param_grid}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd002fbb",
   "metadata": {},
   "source": [
    "## MLflow tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7539300e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/24 13:26:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "[('C:\\\\Users\\\\aleja\\\\AppData\\\\Local\\\\Temp\\\\tmprdychz7g\\\\model\\\\sparkml\\\\stages\\\\0_LinearRegression_5e75d3ba3256\\\\data\\\\.part-00000-4dc86174-acc1-4e8f-b532-85e7e5896670-c000.snappy.parquet.crc', 'C:\\\\Users\\\\aleja\\\\OneDrive\\\\Escritorio\\\\Term_3\\\\Big_data_management\\\\Lab_3\\\\Lab3-Assignment\\\\BDM-lab3\\\\mlruns\\\\0\\\\6571a2cc92684531be82a95b1dab2d72\\\\artifacts\\\\model\\\\sparkml\\\\stages\\\\0_LinearRegression_5e75d3ba3256\\\\data\\\\.part-00000-4dc86174-acc1-4e8f-b532-85e7e5896670-c000.snappy.parquet.crc', \"[Errno 2] No such file or directory: 'C:\\\\\\\\Users\\\\\\\\aleja\\\\\\\\OneDrive\\\\\\\\Escritorio\\\\\\\\Term_3\\\\\\\\Big_data_management\\\\\\\\Lab_3\\\\\\\\Lab3-Assignment\\\\\\\\BDM-lab3\\\\\\\\mlruns\\\\\\\\0\\\\\\\\6571a2cc92684531be82a95b1dab2d72\\\\\\\\artifacts\\\\\\\\model\\\\\\\\sparkml\\\\\\\\stages\\\\\\\\0_LinearRegression_5e75d3ba3256\\\\\\\\data\\\\\\\\.part-00000-4dc86174-acc1-4e8f-b532-85e7e5896670-c000.snappy.parquet.crc'\"), ('C:\\\\Users\\\\aleja\\\\AppData\\\\Local\\\\Temp\\\\tmprdychz7g\\\\model\\\\sparkml\\\\stages\\\\0_LinearRegression_5e75d3ba3256\\\\data\\\\part-00000-4dc86174-acc1-4e8f-b532-85e7e5896670-c000.snappy.parquet', 'C:\\\\Users\\\\aleja\\\\OneDrive\\\\Escritorio\\\\Term_3\\\\Big_data_management\\\\Lab_3\\\\Lab3-Assignment\\\\BDM-lab3\\\\mlruns\\\\0\\\\6571a2cc92684531be82a95b1dab2d72\\\\artifacts\\\\model\\\\sparkml\\\\stages\\\\0_LinearRegression_5e75d3ba3256\\\\data\\\\part-00000-4dc86174-acc1-4e8f-b532-85e7e5896670-c000.snappy.parquet', \"[Errno 2] No such file or directory: 'C:\\\\\\\\Users\\\\\\\\aleja\\\\\\\\OneDrive\\\\\\\\Escritorio\\\\\\\\Term_3\\\\\\\\Big_data_management\\\\\\\\Lab_3\\\\\\\\Lab3-Assignment\\\\\\\\BDM-lab3\\\\\\\\mlruns\\\\\\\\0\\\\\\\\6571a2cc92684531be82a95b1dab2d72\\\\\\\\artifacts\\\\\\\\model\\\\\\\\sparkml\\\\\\\\stages\\\\\\\\0_LinearRegression_5e75d3ba3256\\\\\\\\data\\\\\\\\part-00000-4dc86174-acc1-4e8f-b532-85e7e5896670-c000.snappy.parquet'\"), ('C:\\\\Users\\\\aleja\\\\AppData\\\\Local\\\\Temp\\\\tmprdychz7g\\\\model\\\\sparkml\\\\stages\\\\0_LinearRegression_5e75d3ba3256\\\\metadata\\\\.part-00000-84857947-49ab-48e6-963f-aa106e372a85-c000.txt.crc', 'C:\\\\Users\\\\aleja\\\\OneDrive\\\\Escritorio\\\\Term_3\\\\Big_data_management\\\\Lab_3\\\\Lab3-Assignment\\\\BDM-lab3\\\\mlruns\\\\0\\\\6571a2cc92684531be82a95b1dab2d72\\\\artifacts\\\\model\\\\sparkml\\\\stages\\\\0_LinearRegression_5e75d3ba3256\\\\metadata\\\\.part-00000-84857947-49ab-48e6-963f-aa106e372a85-c000.txt.crc', \"[Errno 2] No such file or directory: 'C:\\\\\\\\Users\\\\\\\\aleja\\\\\\\\OneDrive\\\\\\\\Escritorio\\\\\\\\Term_3\\\\\\\\Big_data_management\\\\\\\\Lab_3\\\\\\\\Lab3-Assignment\\\\\\\\BDM-lab3\\\\\\\\mlruns\\\\\\\\0\\\\\\\\6571a2cc92684531be82a95b1dab2d72\\\\\\\\artifacts\\\\\\\\model\\\\\\\\sparkml\\\\\\\\stages\\\\\\\\0_LinearRegression_5e75d3ba3256\\\\\\\\metadata\\\\\\\\.part-00000-84857947-49ab-48e6-963f-aa106e372a85-c000.txt.crc'\"), ('C:\\\\Users\\\\aleja\\\\AppData\\\\Local\\\\Temp\\\\tmprdychz7g\\\\model\\\\sparkml\\\\stages\\\\0_LinearRegression_5e75d3ba3256\\\\metadata\\\\part-00000-84857947-49ab-48e6-963f-aa106e372a85-c000.txt', 'C:\\\\Users\\\\aleja\\\\OneDrive\\\\Escritorio\\\\Term_3\\\\Big_data_management\\\\Lab_3\\\\Lab3-Assignment\\\\BDM-lab3\\\\mlruns\\\\0\\\\6571a2cc92684531be82a95b1dab2d72\\\\artifacts\\\\model\\\\sparkml\\\\stages\\\\0_LinearRegression_5e75d3ba3256\\\\metadata\\\\part-00000-84857947-49ab-48e6-963f-aa106e372a85-c000.txt', \"[Errno 2] No such file or directory: 'C:\\\\\\\\Users\\\\\\\\aleja\\\\\\\\OneDrive\\\\\\\\Escritorio\\\\\\\\Term_3\\\\\\\\Big_data_management\\\\\\\\Lab_3\\\\\\\\Lab3-Assignment\\\\\\\\BDM-lab3\\\\\\\\mlruns\\\\\\\\0\\\\\\\\6571a2cc92684531be82a95b1dab2d72\\\\\\\\artifacts\\\\\\\\model\\\\\\\\sparkml\\\\\\\\stages\\\\\\\\0_LinearRegression_5e75d3ba3256\\\\\\\\metadata\\\\\\\\part-00000-84857947-49ab-48e6-963f-aa106e372a85-c000.txt'\")]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mError\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_metric(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrmse\u001b[39m\u001b[38;5;124m\"\u001b[39m, rmse)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Log model\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Store best model for later ranking/deployment\u001b[39;00m\n\u001b[0;32m     34\u001b[0m best_models[model_name] \u001b[38;5;241m=\u001b[39m (best_model, rmse)\n",
      "File \u001b[1;32mc:\\Users\\aleja\\anaconda3\\envs\\myenv\\lib\\site-packages\\mlflow\\spark\\__init__.py:341\u001b[0m, in \u001b[0;36mlog_model\u001b[1;34m(spark_model, artifact_path, conda_env, code_paths, dfs_tmpdir, sample_input, registered_model_name, signature, input_example, await_registration_for, pip_requirements, extra_pip_requirements, metadata)\u001b[0m\n\u001b[0;32m    339\u001b[0m     dfs_tmpdir \u001b[38;5;241m=\u001b[39m dfs_tmpdir \u001b[38;5;129;01mor\u001b[39;00m MLFLOW_DFS_TMP\u001b[38;5;241m.\u001b[39mget()\n\u001b[0;32m    340\u001b[0m     _check_databricks_uc_volume_tmpdir_availability(dfs_tmpdir)\n\u001b[1;32m--> 341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m        \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mflavor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspark\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspark_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspark_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconda_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconda_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcode_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdfs_tmpdir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdfs_tmpdir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m        \u001b[49m\u001b[43mregistered_model_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mregistered_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m        \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_example\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_example\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mawait_registration_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mawait_registration_for\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpip_requirements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;66;03m# Otherwise, override the default model log behavior and save model directly to artifact repo\u001b[39;00m\n\u001b[0;32m    358\u001b[0m mlflow_model \u001b[38;5;241m=\u001b[39m Model(artifact_path\u001b[38;5;241m=\u001b[39martifact_path, run_id\u001b[38;5;241m=\u001b[39mrun_id)\n",
      "File \u001b[1;32mc:\\Users\\aleja\\anaconda3\\envs\\myenv\\lib\\site-packages\\mlflow\\models\\model.py:921\u001b[0m, in \u001b[0;36mModel.log\u001b[1;34m(cls, artifact_path, flavor, registered_model_name, await_registration_for, metadata, run_id, resources, auth_policy, prompts, **kwargs)\u001b[0m\n\u001b[0;32m    918\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[0;32m    919\u001b[0m         client\u001b[38;5;241m.\u001b[39mlog_prompt(run_id, prompt)\n\u001b[1;32m--> 921\u001b[0m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtracking\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfluent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_artifacts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlflow_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[38;5;66;03m# if the model_config kwarg is passed in, then log the model config as an params\u001b[39;00m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_config \u001b[38;5;241m:=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_config\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\aleja\\anaconda3\\envs\\myenv\\lib\\site-packages\\mlflow\\tracking\\fluent.py:1219\u001b[0m, in \u001b[0;36mlog_artifacts\u001b[1;34m(local_dir, artifact_path, run_id)\u001b[0m\n\u001b[0;32m   1185\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;124;03mLog all the contents of a local directory as artifacts of the run. If no run is active,\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;124;03mthis method will create a new active run.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;124;03m            mlflow.log_artifacts(tmp_dir, artifact_path=\"states\")\u001b[39;00m\n\u001b[0;32m   1217\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1218\u001b[0m run_id \u001b[38;5;241m=\u001b[39m run_id \u001b[38;5;129;01mor\u001b[39;00m _get_or_start_run()\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id\n\u001b[1;32m-> 1219\u001b[0m \u001b[43mMlflowClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_artifacts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aleja\\anaconda3\\envs\\myenv\\lib\\site-packages\\mlflow\\tracking\\client.py:2428\u001b[0m, in \u001b[0;36mMlflowClient.log_artifacts\u001b[1;34m(self, run_id, local_dir, artifact_path)\u001b[0m\n\u001b[0;32m   2381\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_artifacts\u001b[39m(\n\u001b[0;32m   2382\u001b[0m     \u001b[38;5;28mself\u001b[39m, run_id: \u001b[38;5;28mstr\u001b[39m, local_dir: \u001b[38;5;28mstr\u001b[39m, artifact_path: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Write a directory of files to the remote ``artifact_uri``.\u001b[39;00m\n\u001b[0;32m   2385\u001b[0m \n\u001b[0;32m   2386\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2426\u001b[0m \n\u001b[0;32m   2427\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2428\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tracking_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_artifacts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aleja\\anaconda3\\envs\\myenv\\lib\\site-packages\\mlflow\\tracking\\_tracking_service\\client.py:964\u001b[0m, in \u001b[0;36mTrackingServiceClient.log_artifacts\u001b[1;34m(self, run_id, local_dir, artifact_path)\u001b[0m\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_artifacts\u001b[39m(\u001b[38;5;28mself\u001b[39m, run_id, local_dir, artifact_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    956\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Write a directory of files to the remote ``artifact_uri``.\u001b[39;00m\n\u001b[0;32m    957\u001b[0m \n\u001b[0;32m    958\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    962\u001b[0m \n\u001b[0;32m    963\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 964\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_artifact_repo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_artifacts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aleja\\anaconda3\\envs\\myenv\\lib\\site-packages\\mlflow\\store\\artifact\\local_artifact_repo.py:67\u001b[0m, in \u001b[0;36mLocalArtifactRepository.log_artifacts\u001b[1;34m(self, local_dir, artifact_path)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(artifact_dir):\n\u001b[0;32m     66\u001b[0m     mkdir(artifact_dir)\n\u001b[1;32m---> 67\u001b[0m \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopytree\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifact_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirs_exist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aleja\\anaconda3\\envs\\myenv\\lib\\shutil.py:568\u001b[0m, in \u001b[0;36mcopytree\u001b[1;34m(src, dst, symlinks, ignore, copy_function, ignore_dangling_symlinks, dirs_exist_ok)\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m os\u001b[38;5;241m.\u001b[39mscandir(src) \u001b[38;5;28;01mas\u001b[39;00m itr:\n\u001b[0;32m    567\u001b[0m     entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(itr)\n\u001b[1;32m--> 568\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_copytree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mentries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mentries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msymlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msymlinks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mignore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mignore_dangling_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_dangling_symlinks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mdirs_exist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirs_exist_ok\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aleja\\anaconda3\\envs\\myenv\\lib\\shutil.py:522\u001b[0m, in \u001b[0;36m_copytree\u001b[1;34m(entries, src, dst, symlinks, ignore, copy_function, ignore_dangling_symlinks, dirs_exist_ok)\u001b[0m\n\u001b[0;32m    520\u001b[0m         errors\u001b[38;5;241m.\u001b[39mappend((src, dst, \u001b[38;5;28mstr\u001b[39m(why)))\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m errors:\n\u001b[1;32m--> 522\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Error(errors)\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dst\n",
      "\u001b[1;31mError\u001b[0m: [('C:\\\\Users\\\\aleja\\\\AppData\\\\Local\\\\Temp\\\\tmprdychz7g\\\\model\\\\sparkml\\\\stages\\\\0_LinearRegression_5e75d3ba3256\\\\data\\\\.part-00000-4dc86174-acc1-4e8f-b532-85e7e5896670-c000.snappy.parquet.crc', 'C:\\\\Users\\\\aleja\\\\OneDrive\\\\Escritorio\\\\Term_3\\\\Big_data_management\\\\Lab_3\\\\Lab3-Assignment\\\\BDM-lab3\\\\mlruns\\\\0\\\\6571a2cc92684531be82a95b1dab2d72\\\\artifacts\\\\model\\\\sparkml\\\\stages\\\\0_LinearRegression_5e75d3ba3256\\\\data\\\\.part-00000-4dc86174-acc1-4e8f-b532-85e7e5896670-c000.snappy.parquet.crc', \"[Errno 2] No such file or directory: 'C:\\\\\\\\Users\\\\\\\\aleja\\\\\\\\OneDrive\\\\\\\\Escritorio\\\\\\\\Term_3\\\\\\\\Big_data_management\\\\\\\\Lab_3\\\\\\\\Lab3-Assignment\\\\\\\\BDM-lab3\\\\\\\\mlruns\\\\\\\\0\\\\\\\\6571a2cc92684531be82a95b1dab2d72\\\\\\\\artifacts\\\\\\\\model\\\\\\\\sparkml\\\\\\\\stages\\\\\\\\0_LinearRegression_5e75d3ba3256\\\\\\\\data\\\\\\\\.part-00000-4dc86174-acc1-4e8f-b532-85e7e5896670-c000.snappy.parquet.crc'\"), ('C:\\\\Users\\\\aleja\\\\AppData\\\\Local\\\\Temp\\\\tmprdychz7g\\\\model\\\\sparkml\\\\stages\\\\0_LinearRegression_5e75d3ba3256\\\\data\\\\part-00000-4dc86174-acc1-4e8f-b532-85e7e5896670-c000.snappy.parquet', 'C:\\\\Users\\\\aleja\\\\OneDrive\\\\Escritorio\\\\Term_3\\\\Big_data_management\\\\Lab_3\\\\Lab3-Assignment\\\\BDM-lab3\\\\mlruns\\\\0\\\\6571a2cc92684531be82a95b1dab2d72\\\\artifacts\\\\model\\\\sparkml\\\\stages\\\\0_LinearRegression_5e75d3ba3256\\\\data\\\\part-00000-4dc86174-acc1-4e8f-b532-85e7e5896670-c000.snappy.parquet', \"[Errno 2] No such file or directory: 'C:\\\\\\\\Users\\\\\\\\aleja\\\\\\\\OneDrive\\\\\\\\Escritorio\\\\\\\\Term_3\\\\\\\\Big_data_management\\\\\\\\Lab_3\\\\\\\\Lab3-Assignment\\\\\\\\BDM-lab3\\\\\\\\mlruns\\\\\\\\0\\\\\\\\6571a2cc92684531be82a95b1dab2d72\\\\\\\\artifacts\\\\\\\\model\\\\\\\\sparkml\\\\\\\\stages\\\\\\\\0_LinearRegression_5e75d3ba3256\\\\\\\\data\\\\\\\\part-00000-4dc86174-acc1-4e8f-b532-85e7e5896670-c000.snappy.parquet'\"), ('C:\\\\Users\\\\aleja\\\\AppData\\\\Local\\\\Temp\\\\tmprdychz7g\\\\model\\\\sparkml\\\\stages\\\\0_LinearRegression_5e75d3ba3256\\\\metadata\\\\.part-00000-84857947-49ab-48e6-963f-aa106e372a85-c000.txt.crc', 'C:\\\\Users\\\\aleja\\\\OneDrive\\\\Escritorio\\\\Term_3\\\\Big_data_management\\\\Lab_3\\\\Lab3-Assignment\\\\BDM-lab3\\\\mlruns\\\\0\\\\6571a2cc92684531be82a95b1dab2d72\\\\artifacts\\\\model\\\\sparkml\\\\stages\\\\0_LinearRegression_5e75d3ba3256\\\\metadata\\\\.part-00000-84857947-49ab-48e6-963f-aa106e372a85-c000.txt.crc', \"[Errno 2] No such file or directory: 'C:\\\\\\\\Users\\\\\\\\aleja\\\\\\\\OneDrive\\\\\\\\Escritorio\\\\\\\\Term_3\\\\\\\\Big_data_management\\\\\\\\Lab_3\\\\\\\\Lab3-Assignment\\\\\\\\BDM-lab3\\\\\\\\mlruns\\\\\\\\0\\\\\\\\6571a2cc92684531be82a95b1dab2d72\\\\\\\\artifacts\\\\\\\\model\\\\\\\\sparkml\\\\\\\\stages\\\\\\\\0_LinearRegression_5e75d3ba3256\\\\\\\\metadata\\\\\\\\.part-00000-84857947-49ab-48e6-963f-aa106e372a85-c000.txt.crc'\"), ('C:\\\\Users\\\\aleja\\\\AppData\\\\Local\\\\Temp\\\\tmprdychz7g\\\\model\\\\sparkml\\\\stages\\\\0_LinearRegression_5e75d3ba3256\\\\metadata\\\\part-00000-84857947-49ab-48e6-963f-aa106e372a85-c000.txt', 'C:\\\\Users\\\\aleja\\\\OneDrive\\\\Escritorio\\\\Term_3\\\\Big_data_management\\\\Lab_3\\\\Lab3-Assignment\\\\BDM-lab3\\\\mlruns\\\\0\\\\6571a2cc92684531be82a95b1dab2d72\\\\artifacts\\\\model\\\\sparkml\\\\stages\\\\0_LinearRegression_5e75d3ba3256\\\\metadata\\\\part-00000-84857947-49ab-48e6-963f-aa106e372a85-c000.txt', \"[Errno 2] No such file or directory: 'C:\\\\\\\\Users\\\\\\\\aleja\\\\\\\\OneDrive\\\\\\\\Escritorio\\\\\\\\Term_3\\\\\\\\Big_data_management\\\\\\\\Lab_3\\\\\\\\Lab3-Assignment\\\\\\\\BDM-lab3\\\\\\\\mlruns\\\\\\\\0\\\\\\\\6571a2cc92684531be82a95b1dab2d72\\\\\\\\artifacts\\\\\\\\model\\\\\\\\sparkml\\\\\\\\stages\\\\\\\\0_LinearRegression_5e75d3ba3256\\\\\\\\metadata\\\\\\\\part-00000-84857947-49ab-48e6-963f-aa106e372a85-c000.txt'\")]"
     ]
    }
   ],
   "source": [
    "# Define evaluators\n",
    "evaluator = RegressionEvaluator(labelCol=\"price_clean\", \n",
    "                                predictionCol=\"prediction\",\n",
    "                                metricName=\"rmse\")\n",
    "best_models = {}\n",
    "\n",
    "for model_name, param_grid in param_grids.items():\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # Set up CrossValidator for each model\n",
    "        cv = CrossValidator(\n",
    "            estimator=models[model_name],\n",
    "            estimatorParamMaps=param_grid,\n",
    "            evaluator=evaluator,\n",
    "            numFolds=3\n",
    "        )\n",
    "        cv_model = cv.fit(train_data)\n",
    "        best_model = cv_model.bestModel\n",
    "\n",
    "        # Predict on validation/test set\n",
    "        predictions = best_model.transform(test_data)\n",
    "        rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "        # Log hyperparameters (from bestModel's params)\n",
    "        for param, value in best_model.extractParamMap().items():\n",
    "            mlflow.log_param(str(param), value)\n",
    "\n",
    "        # Log evaluation metric\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "        # Log model\n",
    "        mlflow.spark.log_model(best_model, \"model\")\n",
    "\n",
    "        # Store best model for later ranking/deployment\n",
    "        best_models[model_name] = (best_model, rmse)\n",
    "        print(f\"{model_name} best RMSE: {rmse:.4f}\")\n",
    "\n",
    "# After all runs, you can rank/select/deploy the best model as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8d277a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Linear Regression on test set\n",
      "  RMSE: €191,385\n",
      "  MAE: €116,727\n",
      "  R²: 0.769\n",
      "\n",
      "Evaluating Random Forest on test set\n",
      "  RMSE: €158,171\n",
      "  MAE: €85,683\n",
      "  R²: 0.842\n",
      "\n",
      "Evaluating Gradient Boosting on test set\n",
      "  RMSE: €164,549\n",
      "  MAE: €93,493\n",
      "  R²: 0.829\n"
     ]
    }
   ],
   "source": [
    "# validate models on test set and calculate metrics \n",
    "\n",
    "# create evaluators for different metrics\n",
    "rmse_evaluator = RegressionEvaluator(labelCol=\"price_clean\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "mae_evaluator = RegressionEvaluator(labelCol=\"price_clean\", predictionCol=\"prediction\", metricName=\"mae\") \n",
    "r2_evaluator = RegressionEvaluator(labelCol=\"price_clean\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "\n",
    "test_results = {}\n",
    "\n",
    "for model_name, model_dict in trained_models.items():\n",
    "    model = model_dict[\"model\"]\n",
    "    \n",
    "    print(f\"\\nEvaluating {model_name} on test set\")\n",
    "    \n",
    "    # make predictions\n",
    "    predictions = model.transform(test_data)\n",
    "    \n",
    "    # calculate metrics\n",
    "    rmse = rmse_evaluator.evaluate(predictions)\n",
    "    mae = mae_evaluator.evaluate(predictions)\n",
    "    r2 = r2_evaluator.evaluate(predictions)\n",
    "    \n",
    "    test_results[model_name] = {\n",
    "        \"rmse\": rmse,\n",
    "        \"mae\": mae, \n",
    "        \"r2\": r2,\n",
    "        \"predictions\": predictions}\n",
    "    \n",
    "    print(f\"  RMSE: €{rmse:,.0f}\")\n",
    "    print(f\"  MAE: €{mae:,.0f}\")\n",
    "    print(f\"  R²: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "caa429d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                    MODEL PERFORMANCE COMPARISON\n",
      "================================================================================\n",
      "Model                CV RMSE      Test RMSE    Test MAE     Test R²   \n",
      "--------------------------------------------------------------------------------\n",
      "Linear Regression    193,145      191,385      116,727      0.769     \n",
      "Random Forest        165,725      158,171      85,683       0.842     \n",
      "Gradient Boosting    184,602      164,549      93,493       0.829     \n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# compare performance of models\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"                    MODEL PERFORMANCE COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"{'Model':<20} {'CV RMSE':<12} {'Test RMSE':<12} {'Test MAE':<12} {'Test R²':<10}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "best_model_name = None\n",
    "best_rmse = float('inf')\n",
    "\n",
    "for model_name in model_metrics.keys():\n",
    "    cv_rmse = model_metrics[model_name][\"cv_rmse\"]\n",
    "    test_rmse = test_results[model_name][\"rmse\"]\n",
    "    test_mae = test_results[model_name][\"mae\"]\n",
    "    test_r2 = test_results[model_name][\"r2\"]\n",
    "    \n",
    "    print(f\"{model_name:<20} {cv_rmse:<12,.0f} {test_rmse:<12,.0f} {test_mae:<12,.0f} {test_r2:<10.3f}\")\n",
    "    \n",
    "    # track best model by test RMSE\n",
    "    if test_rmse < best_rmse:\n",
    "        best_rmse = test_rmse\n",
    "        best_model_name = model_name\n",
    "\n",
    "print(\"-\"*80)\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fdf3dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best model\n",
    "best_model = trained_models[best_model_name][\"model\"]\n",
    "best_model.write().overwrite().save(f\"{exploitation_zone}/best_model\")\n",
    "\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
