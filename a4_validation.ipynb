{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fee652f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, sum as spark_sum, avg, min as spark_min, max as spark_max, stddev, isnan, isnull, when\n",
    "from pyspark.sql.types import NumericType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15b64a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/06/23 14:40:07 WARN Utils: Your hostname, MacBook-Air.local, resolves to a loopback address: 127.0.0.1; using 192.168.1.134 instead (on interface en0)\n",
      "25/06/23 14:40:07 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/23 14:40:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# set spark session \n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"DataValidation\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2e920d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths for the zones\n",
    "formatted_zone = \"formatted_zone\"\n",
    "exploitation_zone = \"exploitation_zone\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f836c821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in formatted data:\n",
      "   1. Poblacio_average          : double\n",
      "   2. Index_RFD_average         : double\n",
      "   3. address                   : string\n",
      "   4. bathrooms                 : bigint\n",
      "   5. country                   : string\n",
      "   6. detailedType              : struct<subTypology:string,typology:string>\n",
      "   7. distance                  : string\n",
      "   8. exterior                  : boolean\n",
      "   9. floor                     : string\n",
      "  10. has360                    : boolean\n",
      "  11. has3DTour                 : boolean\n",
      "  12. hasLift                   : boolean\n",
      "  13. hasPlan                   : boolean\n",
      "  14. hasStaging                : boolean\n",
      "  15. hasVideo                  : boolean\n",
      "  16. latitude                  : double\n",
      "  17. longitude                 : double\n",
      "  18. municipality              : string\n",
      "  19. newDevelopment            : boolean\n",
      "  20. newDevelopmentFinished    : boolean\n",
      "  21. numPhotos                 : bigint\n",
      "  22. operation                 : string\n",
      "  23. parkingSpace              : struct<hasParkingSpace:boolean,isParkingSpaceIncludedInPrice:boolean,parkingSpacePrice:double>\n",
      "  24. price                     : double\n",
      "  25. priceByArea               : double\n",
      "  26. propertyCode              : string\n",
      "  27. propertyType              : string\n",
      "  28. province                  : string\n",
      "  29. rooms                     : bigint\n",
      "  30. showAddress               : boolean\n",
      "  31. size                      : double\n",
      "  32. status                    : string\n",
      "  33. suggestedTexts            : struct<subtitle:string,title:string>\n",
      "  34. topNewDevelopment         : boolean\n",
      "  35. neighborhood_n_reconciled : string\n",
      "  36. neighborhood_id           : string\n",
      "\n",
      "total columns: 36\n"
     ]
    }
   ],
   "source": [
    "# validate data in the formatted zone\n",
    "\n",
    "# load data\n",
    "formatted_data = spark.read.parquet(f\"{formatted_zone}/formatted_data\")\n",
    "\n",
    "# visualize schema\n",
    "print(\"Columns in formatted data:\")\n",
    "for i, (col_name, col_type) in enumerate(formatted_data.dtypes, 1):\n",
    "    print(f\"  {i:2d}. {col_name:<25} : {col_type}\")\n",
    "\n",
    "print(f\"\\ntotal columns: {len(formatted_data.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11951621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Name               Non-Null Count  Null Count   Null %   Data Type      \n",
      "--------------------------------------------------------------------------------\n",
      "Poblacio_average          2,812           0            0.0    % double         \n",
      "Index_RFD_average         2,812           0            0.0    % double         \n",
      "address                   2,812           0            0.0    % string         \n",
      "bathrooms                 2,812           0            0.0    % bigint         \n",
      "country                   2,812           0            0.0    % string         \n",
      "detailedType              2,812           0            0.0    % struct<subTypology:string,typology:string>\n",
      "distance                  2,812           0            0.0    % string         \n",
      "exterior                  2,812           0            0.0    % boolean        \n",
      "floor                     2,262           550          19.6   % string         \n",
      "has360                    2,812           0            0.0    % boolean        \n",
      "has3DTour                 2,812           0            0.0    % boolean        \n",
      "hasLift                   2,430           382          13.6   % boolean        \n",
      "hasPlan                   2,812           0            0.0    % boolean        \n",
      "hasStaging                2,812           0            0.0    % boolean        \n",
      "hasVideo                  2,812           0            0.0    % boolean        \n",
      "latitude                  2,812           0            0.0    % double         \n",
      "longitude                 2,812           0            0.0    % double         \n",
      "municipality              2,812           0            0.0    % string         \n",
      "newDevelopment            2,812           0            0.0    % boolean        \n",
      "newDevelopmentFinished    38              2,774        98.6   % boolean        \n",
      "numPhotos                 2,812           0            0.0    % bigint         \n",
      "operation                 2,812           0            0.0    % string         \n",
      "parkingSpace              676             2,136        76.0   % struct<hasParkingSpace:boolean,isParkingSpaceIncludedInPrice:boolean,parkingSpacePrice:double>\n",
      "price                     2,812           0            0.0    % double         \n",
      "priceByArea               2,812           0            0.0    % double         \n",
      "propertyCode              2,812           0            0.0    % string         \n",
      "propertyType              2,812           0            0.0    % string         \n",
      "province                  2,812           0            0.0    % string         \n",
      "rooms                     2,812           0            0.0    % bigint         \n",
      "showAddress               2,812           0            0.0    % boolean        \n",
      "size                      2,812           0            0.0    % double         \n",
      "status                    2,812           0            0.0    % string         \n",
      "suggestedTexts            2,812           0            0.0    % struct<subtitle:string,title:string>\n",
      "topNewDevelopment         2,812           0            0.0    % boolean        \n",
      "neighborhood_n_reconciled 2,812           0            0.0    % string         \n",
      "neighborhood_id           2,812           0            0.0    % string         \n"
     ]
    }
   ],
   "source": [
    "# verify where we have null values\n",
    "print(f\"{'Column Name':<25} {'Non-Null Count':<15} {'Null Count':<12} {'Null %':<8} {'Data Type':<15}\")\n",
    "print(\"-\" * 80)\n",
    "total_records = formatted_data.count()\n",
    "for col_name, col_type in formatted_data.dtypes:\n",
    "    non_null_count = formatted_data.filter(col(col_name).isNotNull()).count()\n",
    "    null_count = total_records - non_null_count\n",
    "    null_percentage = (null_count / total_records) * 100\n",
    "    \n",
    "    print(f\"{col_name:<25} {non_null_count:<15,} {null_count:<12,} {null_percentage:<7.1f}% {col_type:<15}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3412e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price statistics:\n",
      "  Count: 2,812\n",
      "  Average: €791,569\n",
      "  Min: €69,500\n",
      "  Max: €10,000,000\n",
      "  Std Dev: €1,074,255\n"
     ]
    }
   ],
   "source": [
    "# check statistics for the price column\n",
    "price_stats = formatted_data.select(\n",
    "    count(\"price\").alias(\"count\"),\n",
    "    avg(\"price\").alias(\"avg_price\"),\n",
    "    spark_min(\"price\").alias(\"min_price\"),\n",
    "    spark_max(\"price\").alias(\"max_price\"),\n",
    "    stddev(\"price\").alias(\"std_price\")\n",
    ").collect()[0]\n",
    "\n",
    "print(f\"Price statistics:\")\n",
    "print(f\"  Count: {price_stats['count']:,}\")\n",
    "print(f\"  Average: €{price_stats['avg_price']:,.0f}\")\n",
    "print(f\"  Min: €{price_stats['min_price']:,.0f}\")\n",
    "print(f\"  Max: €{price_stats['max_price']:,.0f}\")\n",
    "print(f\"  Std Dev: €{price_stats['std_price']:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b139198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Income Index statistics:\n",
      "  Count: 2,812\n",
      "  Average Index: 124.7\n",
      "  Min Index: 55.2\n",
      "  Max Index: 229.0\n"
     ]
    }
   ],
   "source": [
    "# check statistics for the income index\n",
    "income_stats = formatted_data.select(\n",
    "    count(\"Index_RFD_average\").alias(\"count\"),\n",
    "    avg(\"Index_RFD_average\").alias(\"avg_income\"),\n",
    "    spark_min(\"Index_RFD_average\").alias(\"min_income\"),\n",
    "    spark_max(\"Index_RFD_average\").alias(\"max_income\")\n",
    ").collect()[0]\n",
    "\n",
    "print(f\"\\nIncome Index statistics:\")\n",
    "print(f\"  Count: {income_stats['count']:,}\")\n",
    "print(f\"  Average Index: {income_stats['avg_income']:.1f}\")\n",
    "print(f\"  Min Index: {income_stats['min_income']:.1f}\")\n",
    "print(f\"  Max Index: {income_stats['max_income']:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bb93334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Neighborhood distribution (top 10):\n",
      "+-----------------------------+-----+\n",
      "|neighborhood_n_reconciled    |count|\n",
      "+-----------------------------+-----+\n",
      "|Sants                        |914  |\n",
      "|Sant Antoni                  |520  |\n",
      "|Sarrià                       |412  |\n",
      "|Pedralbes                    |404  |\n",
      "|Hostafrancs                  |288  |\n",
      "|Vallcarca i els Penitents    |158  |\n",
      "|Can Baró                     |70   |\n",
      "|Porta                        |24   |\n",
      "|Vilapicina i la Torre Llobeta|8    |\n",
      "|Verdun                       |8    |\n",
      "+-----------------------------+-----+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# neighborhood distribution\n",
    "print(f\"\\n>>> Neighborhood distribution (top 10):\")\n",
    "neighborhood_dist = formatted_data.groupBy(\"neighborhood_n_reconciled\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc())\n",
    "\n",
    "neighborhood_dist.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc577fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Property type distribution:\n",
      "+------------+-----+\n",
      "|propertyType|count|\n",
      "+------------+-----+\n",
      "|flat        |2162 |\n",
      "|chalet      |326  |\n",
      "|penthouse   |222  |\n",
      "|duplex      |76   |\n",
      "|studio      |24   |\n",
      "|countryHouse|2    |\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# property type distribution\n",
    "print(f\">>> Property type distribution:\")\n",
    "property_dist = formatted_data.groupBy(\"propertyType\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc())\n",
    "\n",
    "property_dist.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24df5404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate data in the exploitation zone\n",
    "\n",
    "# laod data \n",
    "train_data = spark.read.parquet(f\"{exploitation_zone}/train_data\")\n",
    "test_data = spark.read.parquet(f\"{exploitation_zone}/test_data\")\n",
    "ml_ready_data = spark.read.parquet(f\"{exploitation_zone}/ml_ready_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "735df97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Total ML records: 2,720\n",
      "  Train records: 2,198 (80.8%)\n",
      "  Test records: 522 (19.2%)\n"
     ]
    }
   ],
   "source": [
    "# check the splits\n",
    "total_ml_records = ml_ready_data.count()\n",
    "train_records = train_data.count()\n",
    "test_records = test_data.count()\n",
    "\n",
    "print(f\"  Total ML records: {total_ml_records:,}\")\n",
    "print(f\"  Train records: {train_records:,} ({train_records/total_ml_records*100:.1f}%)\")\n",
    "print(f\"  Test records: {test_records:,} ({test_records/total_ml_records*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0fef861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data columns:\n",
      "root\n",
      " |-- price_clean: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- neighborhood_n_reconciled: string (nullable = true)\n",
      "\n",
      "\n",
      "First feature vector:\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|features                                                                                                                                                                   |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|(50,[0,1,2,3,4,5,6,7,8,12,16,18,26,27,32,34,46,49],[33.0,1.0,1.0,87.79999999999998,41356.72727272727,41.3743657,2.1294698,1959.0,18.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "Vector has 50 dimensions\n"
     ]
    }
   ],
   "source": [
    "# check what columns we have\n",
    "print(\"Train data columns:\")\n",
    "train_data.printSchema()\n",
    "\n",
    "# check feature vector\n",
    "print(\"\\nFirst feature vector:\")\n",
    "train_data.select(\"features\").show(1, truncate=False)\n",
    "\n",
    "# get vector size\n",
    "vector_size = len(train_data.select(\"features\").first()[\"features\"])\n",
    "print(f\"Vector has {vector_size} dimensions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "996c3af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable (=price_clean) statistics:\n",
      "  Count: 2,198\n",
      "  Average: €637,608\n",
      "  Min: €69,500\n",
      "  Max: €3,900,000\n",
      "  Std Dev: €620,758\n"
     ]
    }
   ],
   "source": [
    "# check statistics for the target variable (=price_clean)\n",
    "target_stats = train_data.select(\n",
    "    count(\"price_clean\").alias(\"count\"),\n",
    "    avg(\"price_clean\").alias(\"avg_price\"),\n",
    "    spark_min(\"price_clean\").alias(\"min_price\"),\n",
    "    spark_max(\"price_clean\").alias(\"max_price\"),\n",
    "    stddev(\"price_clean\").alias(\"std_price\")\n",
    ").collect()[0]\n",
    "\n",
    "print(f\"\\nTarget variable (=price_clean) statistics:\")\n",
    "print(f\"  Count: {target_stats['count']:,}\")\n",
    "print(f\"  Average: €{target_stats['avg_price']:,.0f}\")\n",
    "print(f\"  Min: €{target_stats['min_price']:,.0f}\")\n",
    "print(f\"  Max: €{target_stats['max_price']:,.0f}\")\n",
    "print(f\"  Std Dev: €{target_stats['std_price']:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a195000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Null values: 0\n"
     ]
    }
   ],
   "source": [
    "# check for missing values in target\n",
    "null_targets = train_data.filter(col(\"price_clean\").isNull()).count()\n",
    "print(f\"  Null values: {null_targets}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce6d4810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DA QUA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f265b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Formatted Zone: 2,812 records\n",
      "  Exploitation Zone: 2,720 records\n",
      "  Records removed: 92 (3.3%)\n",
      "  Formatted Zone price range: €69,500 - €10,000,000\n",
      "  ML Zone price range: €69,500 - €3,900,000\n"
     ]
    }
   ],
   "source": [
    "# compare record counts between zones\n",
    "formatted_count = formatted_data.count()\n",
    "ml_ready_count = ml_ready_data.count()\n",
    "records_removed = formatted_count - ml_ready_count\n",
    "removal_percentage = (records_removed / formatted_count) * 100\n",
    "\n",
    "print(f\"  Formatted Zone: {formatted_count:,} records\")\n",
    "print(f\"  Exploitation Zone: {ml_ready_count:,} records\")\n",
    "print(f\"  Records removed: {records_removed:,} ({removal_percentage:.1f}%)\")\n",
    "\n",
    "# check price ranges\n",
    "formatted_price_range = formatted_data.select(\n",
    "    spark_min(\"price\").alias(\"min\"), \n",
    "    spark_max(\"price\").alias(\"max\")\n",
    ").collect()[0]\n",
    "\n",
    "ml_price_range = ml_ready_data.select(\n",
    "    spark_min(\"price_clean\").alias(\"min\"), \n",
    "    spark_max(\"price_clean\").alias(\"max\")\n",
    ").collect()[0]\n",
    "\n",
    "print(f\"  Formatted Zone price range: €{formatted_price_range['min']:,.0f} - €{formatted_price_range['max']:,.0f}\")\n",
    "print(f\"  ML Zone price range: €{ml_price_range['min']:,.0f} - €{ml_price_range['max']:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db0ae79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
