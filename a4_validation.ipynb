{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a95c993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set HADOOP_HOME to the parent folder of the 'bin' with winutils.exe\n",
    "os.environ[\"HADOOP_HOME\"] = r\"C:\\winutils-master\\hadoop-3.0.0\"\n",
    "os.environ[\"PATH\"] += r\";C:\\winutils-master\\hadoop-3.0.0\\bin\"\n",
    "\n",
    "# (Optional: Set JAVA_HOME if not already set)\n",
    "os.environ[\"JAVA_HOME\"] = r\"C:\\Program Files\\Eclipse Adoptium\\jdk-17.0.15.6-hotspot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fee652f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, sum as spark_sum, avg, min as spark_min, max as spark_max, stddev, isnan, isnull, when\n",
    "from pyspark.sql.types import NumericType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15b64a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set spark session \n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"DataValidation\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2e920d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths for the zones\n",
    "formatted_zone = \"formatted_zone\"\n",
    "exploitation_zone = \"exploitation_zone\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f836c821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in formatted data:\n",
      "   1. bathrooms                 : bigint\n",
      "   2. distance                  : string\n",
      "   3. district                  : string\n",
      "   4. exterior                  : boolean\n",
      "   5. floor                     : string\n",
      "   6. has360                    : boolean\n",
      "   7. has3DTour                 : boolean\n",
      "   8. hasLift                   : boolean\n",
      "   9. hasPlan                   : boolean\n",
      "  10. hasStaging                : boolean\n",
      "  11. hasVideo                  : boolean\n",
      "  12. latitude                  : double\n",
      "  13. longitude                 : double\n",
      "  14. neighborhood              : string\n",
      "  15. newDevelopment            : boolean\n",
      "  16. newDevelopmentFinished    : boolean\n",
      "  17. numPhotos                 : bigint\n",
      "  18. parkingSpace              : struct<hasParkingSpace:boolean,isParkingSpaceIncludedInPrice:boolean,parkingSpacePrice:double>\n",
      "  19. price                     : double\n",
      "  20. priceByArea               : double\n",
      "  21. propertyCode              : string\n",
      "  22. propertyType              : string\n",
      "  23. rooms                     : bigint\n",
      "  24. showAddress               : boolean\n",
      "  25. size                      : double\n",
      "  26. status                    : string\n",
      "  27. topNewDevelopment         : boolean\n",
      "  28. neighborhood_id           : string\n",
      "  29. Index_RFD_average         : double\n",
      "  30. Poblacio_average          : double\n",
      "\n",
      "total columns: 30\n"
     ]
    }
   ],
   "source": [
    "# validate data in the formatted zone\n",
    "\n",
    "# load data\n",
    "formatted_data = spark.read.parquet(f\"{formatted_zone}/formatted_data\")\n",
    "\n",
    "# visualize schema\n",
    "print(\"Columns in formatted data:\")\n",
    "for i, (col_name, col_type) in enumerate(formatted_data.dtypes, 1):\n",
    "    print(f\"  {i:2d}. {col_name:<25} : {col_type}\")\n",
    "\n",
    "print(f\"\\ntotal columns: {len(formatted_data.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11951621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Name               Non-Null Count  Null Count   Null %   Data Type      \n",
      "--------------------------------------------------------------------------------\n",
      "bathrooms                 4,062           0            0.0    % bigint         \n",
      "distance                  4,062           0            0.0    % string         \n",
      "district                  4,062           0            0.0    % string         \n",
      "exterior                  4,062           0            0.0    % boolean        \n",
      "floor                     3,486           576          14.2   % string         \n",
      "has360                    4,062           0            0.0    % boolean        \n",
      "has3DTour                 4,062           0            0.0    % boolean        \n",
      "hasLift                   3,736           326          8.0    % boolean        \n",
      "hasPlan                   4,062           0            0.0    % boolean        \n",
      "hasStaging                4,062           0            0.0    % boolean        \n",
      "hasVideo                  4,062           0            0.0    % boolean        \n",
      "latitude                  4,062           0            0.0    % double         \n",
      "longitude                 4,062           0            0.0    % double         \n",
      "neighborhood              4,062           0            0.0    % string         \n",
      "newDevelopment            4,062           0            0.0    % boolean        \n",
      "newDevelopmentFinished    103             3,959        97.5   % boolean        \n",
      "numPhotos                 4,062           0            0.0    % bigint         \n",
      "parkingSpace              578             3,484        85.8   % struct<hasParkingSpace:boolean,isParkingSpaceIncludedInPrice:boolean,parkingSpacePrice:double>\n",
      "price                     4,062           0            0.0    % double         \n",
      "priceByArea               4,062           0            0.0    % double         \n",
      "propertyCode              4,062           0            0.0    % string         \n",
      "propertyType              4,062           0            0.0    % string         \n",
      "rooms                     4,062           0            0.0    % bigint         \n",
      "showAddress               4,062           0            0.0    % boolean        \n",
      "size                      4,062           0            0.0    % double         \n",
      "status                    4,062           0            0.0    % string         \n",
      "topNewDevelopment         4,062           0            0.0    % boolean        \n",
      "neighborhood_id           4,062           0            0.0    % string         \n",
      "Index_RFD_average         4,062           0            0.0    % double         \n",
      "Poblacio_average          4,062           0            0.0    % double         \n"
     ]
    }
   ],
   "source": [
    "# verify where we have null values\n",
    "print(f\"{'Column Name':<25} {'Non-Null Count':<15} {'Null Count':<12} {'Null %':<8} {'Data Type':<15}\")\n",
    "print(\"-\" * 80)\n",
    "total_records = formatted_data.count()\n",
    "for col_name, col_type in formatted_data.dtypes:\n",
    "    non_null_count = formatted_data.filter(col(col_name).isNotNull()).count()\n",
    "    null_count = total_records - non_null_count\n",
    "    null_percentage = (null_count / total_records) * 100\n",
    "    \n",
    "    print(f\"{col_name:<25} {non_null_count:<15,} {null_count:<12,} {null_percentage:<7.1f}% {col_type:<15}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3412e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price statistics:\n",
      "  Count: 4,062\n",
      "  Average: €579,315\n",
      "  Min: €34,000\n",
      "  Max: €12,000,000\n",
      "  Std Dev: €683,459\n"
     ]
    }
   ],
   "source": [
    "# check statistics for the price column\n",
    "price_stats = formatted_data.select(\n",
    "    count(\"price\").alias(\"count\"),\n",
    "    avg(\"price\").alias(\"avg_price\"),\n",
    "    spark_min(\"price\").alias(\"min_price\"),\n",
    "    spark_max(\"price\").alias(\"max_price\"),\n",
    "    stddev(\"price\").alias(\"std_price\")\n",
    ").collect()[0]\n",
    "\n",
    "print(f\"Price statistics:\")\n",
    "print(f\"  Count: {price_stats['count']:,}\")\n",
    "print(f\"  Average: €{price_stats['avg_price']:,.0f}\")\n",
    "print(f\"  Min: €{price_stats['min_price']:,.0f}\")\n",
    "print(f\"  Max: €{price_stats['max_price']:,.0f}\")\n",
    "print(f\"  Std Dev: €{price_stats['std_price']:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b139198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Income Index statistics:\n",
      "  Count: 4,062\n",
      "  Average Index: 108.0\n",
      "  Min Index: 43.6\n",
      "  Max Index: 229.0\n"
     ]
    }
   ],
   "source": [
    "# check statistics for the income index\n",
    "income_stats = formatted_data.select(\n",
    "    count(\"Index_RFD_average\").alias(\"count\"),\n",
    "    avg(\"Index_RFD_average\").alias(\"avg_income\"),\n",
    "    spark_min(\"Index_RFD_average\").alias(\"min_income\"),\n",
    "    spark_max(\"Index_RFD_average\").alias(\"max_income\")\n",
    ").collect()[0]\n",
    "\n",
    "print(f\"\\nIncome Index statistics:\")\n",
    "print(f\"  Count: {income_stats['count']:,}\")\n",
    "print(f\"  Average Index: {income_stats['avg_income']:.1f}\")\n",
    "print(f\"  Min Index: {income_stats['min_income']:.1f}\")\n",
    "print(f\"  Max Index: {income_stats['max_income']:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7bb93334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Neighborhood distribution (top 10):\n",
      "+-------------------------------+-----+\n",
      "|neighborhood                   |count|\n",
      "+-------------------------------+-----+\n",
      "|La Dreta de l'Eixample         |352  |\n",
      "|Sants                          |346  |\n",
      "|El Poble Sec - Parc de Montjuïc|300  |\n",
      "|La Nova Esquerra de l'Eixample |298  |\n",
      "|La Marina del Port             |231  |\n",
      "|La Maternitat i Sant Ramon     |229  |\n",
      "|Sants - Badal                  |226  |\n",
      "|El Gòtic                       |218  |\n",
      "|Les Corts                      |214  |\n",
      "|La Bordeta                     |201  |\n",
      "+-------------------------------+-----+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# neighborhood distribution\n",
    "print(f\"\\n>>> Neighborhood distribution (top 10):\")\n",
    "neighborhood_dist = formatted_data.groupBy(\"neighborhood\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc())\n",
    "\n",
    "neighborhood_dist.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc577fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Property type distribution:\n",
      "+------------+-----+\n",
      "|propertyType|count|\n",
      "+------------+-----+\n",
      "|flat        |3421 |\n",
      "|penthouse   |231  |\n",
      "|chalet      |216  |\n",
      "|duplex      |127  |\n",
      "|studio      |66   |\n",
      "|countryHouse|1    |\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# property type distribution\n",
    "print(f\">>> Property type distribution:\")\n",
    "property_dist = formatted_data.groupBy(\"propertyType\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc())\n",
    "\n",
    "property_dist.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24df5404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate data in the exploitation zone\n",
    "\n",
    "# laod data \n",
    "train_data = spark.read.parquet(f\"{exploitation_zone}/train_data\")\n",
    "test_data = spark.read.parquet(f\"{exploitation_zone}/test_data\")\n",
    "ml_ready_data = spark.read.parquet(f\"{exploitation_zone}/ml_ready_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "735df97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Total ML records: 3,950\n",
      "  Train records: 3,219 (81.5%)\n",
      "  Test records: 731 (18.5%)\n"
     ]
    }
   ],
   "source": [
    "# check the splits\n",
    "total_ml_records = ml_ready_data.count()\n",
    "train_records = train_data.count()\n",
    "test_records = test_data.count()\n",
    "\n",
    "print(f\"  Total ML records: {total_ml_records:,}\")\n",
    "print(f\"  Train records: {train_records:,} ({train_records/total_ml_records*100:.1f}%)\")\n",
    "print(f\"  Test records: {test_records:,} ({test_records/total_ml_records*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0fef861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data columns:\n",
      "root\n",
      " |-- price_clean: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- neighborhood: string (nullable = true)\n",
      "\n",
      "\n",
      "First feature vector:\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|features                                                                                                                               |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|(91,[0,3,4,5,6,7,8,12,22,26,28,32,37,89],[10.0,110.32727272727271,58016.0,41.3830747,2.1486212,3228.0,8.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "Vector has 91 dimensions\n"
     ]
    }
   ],
   "source": [
    "# check what columns we have\n",
    "print(\"Train data columns:\")\n",
    "train_data.printSchema()\n",
    "\n",
    "# check feature vector\n",
    "print(\"\\nFirst feature vector:\")\n",
    "train_data.select(\"features\").show(1, truncate=False)\n",
    "\n",
    "# get vector size\n",
    "vector_size = len(train_data.select(\"features\").first()[\"features\"])\n",
    "print(f\"Vector has {vector_size} dimensions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "996c3af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable (=price_clean) statistics:\n",
      "  Count: 3,219\n",
      "  Average: €499,316\n",
      "  Min: €34,000\n",
      "  Max: €2,600,000\n",
      "  Std Dev: €409,612\n"
     ]
    }
   ],
   "source": [
    "# check statistics for the target variable (=price_clean)\n",
    "target_stats = train_data.select(\n",
    "    count(\"price_clean\").alias(\"count\"),\n",
    "    avg(\"price_clean\").alias(\"avg_price\"),\n",
    "    spark_min(\"price_clean\").alias(\"min_price\"),\n",
    "    spark_max(\"price_clean\").alias(\"max_price\"),\n",
    "    stddev(\"price_clean\").alias(\"std_price\")\n",
    ").collect()[0]\n",
    "\n",
    "print(f\"\\nTarget variable (=price_clean) statistics:\")\n",
    "print(f\"  Count: {target_stats['count']:,}\")\n",
    "print(f\"  Average: €{target_stats['avg_price']:,.0f}\")\n",
    "print(f\"  Min: €{target_stats['min_price']:,.0f}\")\n",
    "print(f\"  Max: €{target_stats['max_price']:,.0f}\")\n",
    "print(f\"  Std Dev: €{target_stats['std_price']:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a195000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Null values: 0\n"
     ]
    }
   ],
   "source": [
    "# check for missing values in target\n",
    "null_targets = train_data.filter(col(\"price_clean\").isNull()).count()\n",
    "print(f\"  Null values: {null_targets}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce6d4810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DA QUA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f265b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Formatted Zone: 4,062 records\n",
      "  Exploitation Zone: 3,950 records\n",
      "  Records removed: 112 (2.8%)\n",
      "  Formatted Zone price range: €34,000 - €12,000,000\n",
      "  ML Zone price range: €34,000 - €2,600,000\n"
     ]
    }
   ],
   "source": [
    "# compare record counts between zones\n",
    "formatted_count = formatted_data.count()\n",
    "ml_ready_count = ml_ready_data.count()\n",
    "records_removed = formatted_count - ml_ready_count\n",
    "removal_percentage = (records_removed / formatted_count) * 100\n",
    "\n",
    "print(f\"  Formatted Zone: {formatted_count:,} records\")\n",
    "print(f\"  Exploitation Zone: {ml_ready_count:,} records\")\n",
    "print(f\"  Records removed: {records_removed:,} ({removal_percentage:.1f}%)\")\n",
    "\n",
    "# check price ranges\n",
    "formatted_price_range = formatted_data.select(\n",
    "    spark_min(\"price\").alias(\"min\"), \n",
    "    spark_max(\"price\").alias(\"max\")\n",
    ").collect()[0]\n",
    "\n",
    "ml_price_range = ml_ready_data.select(\n",
    "    spark_min(\"price_clean\").alias(\"min\"), \n",
    "    spark_max(\"price_clean\").alias(\"max\")\n",
    ").collect()[0]\n",
    "\n",
    "print(f\"  Formatted Zone price range: €{formatted_price_range['min']:,.0f} - €{formatted_price_range['max']:,.0f}\")\n",
    "print(f\"  ML Zone price range: €{ml_price_range['min']:,.0f} - €{ml_price_range['max']:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db0ae79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
